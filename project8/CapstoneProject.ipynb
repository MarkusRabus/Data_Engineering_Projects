{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project we will collect data sets and create tables which will allow to assess the influence of solar flares on weathern patterns on Earth. An investigation showed that small fluctuations in spot coverage can influence the climate.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import os, glob\n",
    "import shutil\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In order to evaluate the influence of sunspot coverage on earth weather patter we combined data from two sources. For one, we need the time series for the sun spot coverage and the other data which logs the weather.\n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Two data sets are used:\n",
    "\n",
    "* Sunspots ([link](https://www.kaggle.com/robervalt/sunspots)): This dataset is a csv file with the date and the montly mean total sunspot number as obtained by the Database from SIDC - Solar Influences Data Analysis Center - the solar physics research department of the Royal Observatory of Belgium.\n",
    "\n",
    "* NOAA GSOD ([link](https://data.noaa.gov/dataset/dataset/global-surface-summary-of-the-day-gsod)): This is a public data set from the National Oceanic and Atmospheric Administration (NOAA). This data set is very large and only a limited data set is on the workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data exploration:\n",
    "\n",
    "We start by understanding the content of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create spark session\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"Comparing solar flares with global weathern pattern\")\\\n",
    "        .enableHiveSupport().getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Read sunspot csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#csvFile = 'hessi.solar.flare.2002to2016.csv'\n",
    "csvFile = 'Sunspots.csv'\n",
    "dfSpots = spark.read.csv(csvFile, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Print the schema, show the size of the data and the date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Monthly Mean Total Sunspot Number: double (nullable = true)\n",
      "\n",
      "3252\n",
      "Row(_c0=0, Date=datetime.datetime(1749, 1, 31, 0, 0), Monthly Mean Total Sunspot Number=96.7)\n",
      "+-------------------+\n",
      "|          min(Date)|\n",
      "+-------------------+\n",
      "|1749-01-31 00:00:00|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|          max(Date)|\n",
      "+-------------------+\n",
      "|2019-12-31 00:00:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSpots.printSchema()\n",
    "print(dfSpots.count())\n",
    "print(dfSpots.head())\n",
    "dfSpots.select([min(\"Date\")]).show()\n",
    "dfSpots.select([max(\"Date\")]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "NOAA data is available as `tar.gz` files for each year. We start by exploring only one year. Each `tar.gz` file has several csv files. As an example we start by showing just one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATION: long (nullable = true)\n",
      " |-- DATE: timestamp (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- TEMP_ATTRIBUTES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- DEWP_ATTRIBUTES: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- SLP_ATTRIBUTES: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- STP_ATTRIBUTES: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- VISIB_ATTRIBUTES: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- WDSP_ATTRIBUTES: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- GUST: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MAX_ATTRIBUTES: string (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- MIN_ATTRIBUTES: string (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- PRCP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      "\n",
      "358\n",
      "Row(STATION=68491099999, DATE=datetime.datetime(2016, 1, 1, 0, 0), LATITUDE=-28.2, LONGITUDE=32.4166666, ELEVATION=9.0, NAME='CHARTERS CREEK, SF', TEMP=80.6, TEMP_ATTRIBUTES=8.0, DEWP=66.5, DEWP_ATTRIBUTES=8.0, SLP=1014.6, SLP_ATTRIBUTES=8.0, STP=13.7, STP_ATTRIBUTES=8.0, VISIB=999.9, VISIB_ATTRIBUTES=0.0, WDSP=7.5, WDSP_ATTRIBUTES=8.0, MXSPD=12.0, GUST=999.9, MAX=89.8, MAX_ATTRIBUTES=' ', MIN=73.9, MIN_ATTRIBUTES=' ', PRCP=0.0, PRCP_ATTRIBUTES='I', SNDP=999.9, FRSHTT=0)\n"
     ]
    }
   ],
   "source": [
    "#create a temporary directory where the data will be extracted and explored\n",
    "with tempfile.TemporaryDirectory() as temp_directory:\n",
    "    #unpack to year 2016 data to temporary directory\n",
    "    shutil.unpack_archive('/home/workspace/NOAA_data/2016.tar.gz', temp_directory)\n",
    "    #get a list of all csv files\n",
    "    csvFiles = glob.glob( os.path.join(temp_directory,'*.csv') )\n",
    "    #read the first csv file and print some information\n",
    "    dfNOAA = spark.read.csv(csvFiles[0], header=True, inferSchema=True)\n",
    "    dfNOAA.printSchema()\n",
    "    print(dfNOAA.count())\n",
    "    print(dfNOAA.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "\n",
    "***Columns of interest for NOAA data:***\n",
    "\n",
    "* STATION: Station number (WMO/DATSAV3 number) for the location\n",
    "\n",
    "* DATE: Date of reading\n",
    "\n",
    "* LATITUDE: Station latitude\n",
    "\n",
    "* LONGITUDE: Station longitude\n",
    "\n",
    "* ELEVATION: Station elevation\n",
    "\n",
    "* NAME: Station name\n",
    "\n",
    "* TEMP: Temperature reading\n",
    "\n",
    "* DEWP: Dew Point reading\n",
    "\n",
    "* SLP: Mean sea level pressure for the day in millibars to tenths. Missing = 9999.9\n",
    "\n",
    "* STP: Mean station pressure for the day in millibars to tenths. Missing = 9999.9\n",
    "\n",
    "* VISIB: Mean visibility for the day in miles to tenths. Missing = 999.9\n",
    "\n",
    "* WDSP: Mean wind speed for the day in knots to tenths. Missing = 999.9\n",
    "\n",
    "* MXSPD: Maximum sustained wind speed reported for the day in knots to tenths. Missing = 999.9\n",
    "\n",
    "* GUST: Maximum wind gust reported for the day in knots to tenths. Missing = 999.9\n",
    "\n",
    "* MAX: Maximum temperature reported during the day in Fahrenheit to tenths--time of max temp report varies by country and region.\n",
    "\n",
    "* MIN: Minimum temperature reported during the day in Fahrenheit to tenths--time of min temp report varies by country and region.\n",
    "\n",
    "* PRCP: Total precipitation (rain and/or melted snow) reported during the day in inches and hundredths.\n",
    "\n",
    "\n",
    "***Columns of interest for Sun Spot data:***\n",
    "\n",
    "* _c0: Idenfier\n",
    "* Date: Date\n",
    "* Monthly Mean Total Sunspot Number\n",
    "\n",
    "#### Cleaning Steps\n",
    "\n",
    "For the Sunspot data we only drop duplicate entries and separete date and time column.\n",
    "\n",
    "For the NOAA data we select only columns of interestes, we drop duplicates **and** filter missing values. We iterate over all `tar.gz` files and read all csv files in to a spark dataframe. We will save our staged result in a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- spotId: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- SpotDate: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- SunspotNumber: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3252"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READ sunspot csv file, drop duplicates and add columns dayofmonth, month and year.\n",
    "csvFile = 'Sunspots.csv'\n",
    "dfSpots = spark.read.csv(csvFile, header=True, inferSchema=True)\n",
    "\n",
    "cleanedSpots = dfSpots.select(col('_c0').alias('spotId'), \n",
    "                            col('Date').alias('ts'),\n",
    "                            date_format(dfSpots[\"Date\"], 'yyyy-MM-dd').alias('SpotDate'),\n",
    "                            date_format(dfSpots[\"Date\"], 'h:m:s a').alias('Time'),\n",
    "                            col('Monthly Mean Total Sunspot Number').alias('SunspotNumber'),)\\\n",
    "                            .dropDuplicates()\n",
    "# Show schema for verfication propuses.\n",
    "cleanedSpots.printSchema()\n",
    "# Show number of counts. This table actually has no duplicates.\n",
    "cleanedSpots.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(spotId=653, ts=datetime.datetime(1803, 6, 30, 0, 0), SpotDate='1803-06-30', Time='12:0:0 AM', SunspotNumber=60.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedSpots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Staging the NOAA data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# READ NOAA data.\n",
    "noaaFiles = glob.glob('NOAA_data/*.tar.gz') # List of all tar.gz files\n",
    "for tarfile in noaaFiles[0:3]:\n",
    "    with tempfile.TemporaryDirectory() as temp_directory:\n",
    "        #unpack\n",
    "        shutil.unpack_archive(tarfile, temp_directory)\n",
    "        csvFiles = glob.glob( os.path.join(temp_directory,'*.csv') )\n",
    "        #read all csv files into spark dataframe\n",
    "        dfNOAA = spark.read.csv(csvFiles, header=True, inferSchema=True)\n",
    "        #clean up the data\n",
    "        noaaTable = dfNOAA.select(col('STATION').alias('StationId'), col('DATE').alias('ts'),\n",
    "                                date_format(dfNOAA[\"DATE\"], 'yyyy-MM-dd').alias('Date'),\n",
    "                                date_format(dfNOAA[\"DATE\"], 'h:m:s a').alias('Time'),\n",
    "                                'LATITUDE', 'LONGITUDE', 'ELEVATION',\n",
    "                                'NAME', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', \n",
    "                                'GUST', 'MAX', 'MIN', 'PRCP').dropDuplicates()\\\n",
    "                                .filter(\"SLP != 9999.9\")\\\n",
    "                                .filter(\"STP != 9999.9\")\\\n",
    "                                .filter(\"VISIB != 999.9\")\\\n",
    "                                .filter(\"WDSP != 999.9\")\\\n",
    "                                .filter(\"MXSPD != 999.9\")\\\n",
    "                                .filter(\"GUST != 999.9\")\n",
    "        #Append the data to a parquet file\n",
    "        noaaTable.write.mode('append').parquet(\"NOAA_data.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check that parquet file has been created and the schema is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "noaaParquet = spark.read \\\n",
    "                .format('parquet') \\\n",
    "                .load('NOAA_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- StationId: long (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- GUST: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      "\n",
      "Row(StationId=72250512904, ts=datetime.datetime(2016, 5, 31, 0, 0), Date='2016-05-31', Time='12:0:0 AM', LATITUDE=26.22806, LONGITUDE=-97.65417, ELEVATION=10.4, NAME='HARLINGEN RIO GRANDE VALLEY INTERNATIONAL AIRPORT, TX US', TEMP=83.9, DEWP=74.4, SLP=1010.3, STP=9.0, VISIB=9.5, WDSP=10.0, MXSPD=19.0, GUST=24.1, MAX=93.9, MIN=75.9, PRCP=0.79)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1097077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaaParquet.printSchema()\n",
    "print(noaaParquet.head())\n",
    "noaaParquet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "We use a NoSQL data model, because of the very large NOAA data set. \n",
    "\n",
    "\n",
    "<img src=\"starSchema_capstone.png\">\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "After cleaning the data, we will create a final table which can be queried for each months and it will return sun spot coverage and average weather for each site and globally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model. We start by aggregating the NOAA parquet data and averaging over the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "stationTable = noaaParquet.select('stationId', 'latitude', 'longitude', 'elevation', 'Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "WeatherTable = noaaParquet.select(date_format(noaaParquet[\"ts\"], 'yyyy-MM-dd h:m:s a').alias('ConditionId'), \n",
    "                                'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'GUST', \n",
    "                                'MAX', 'MIN', 'PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dateTable = noaaParquet.select(col('ts'), \n",
    "                                     hour(noaaParquet.ts).alias('hour'), \n",
    "                                     dayofmonth(noaaParquet.ts).alias('day'), \n",
    "                                     weekofyear(noaaParquet.ts).alias('week'),\n",
    "                                     month(noaaParquet.ts).alias('month'),\n",
    "                                     year(noaaParquet.ts).alias('year'),\n",
    "                                     dayofweek(noaaParquet.ts).alias('weekday')) \\\n",
    "                                     .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spotsTable = cleanedSpots.select('spotId','SunspotNumber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We now joint the NOAA and sunspot data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfSpot_join_Weather = noaaParquet.join(cleanedSpots, \n",
    "                (cleanedSpots.SpotDate == noaaParquet.Date) )\\\n",
    "                .drop(cleanedSpots.ts)\\\n",
    "                .sort('Date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(StationId=72522404852, ts=datetime.datetime(2016, 12, 31, 0, 0), Date='2016-12-31', Time='12:0:0 AM', LATITUDE=40.47194, LONGITUDE=-81.42361, ELEVATION=272.8, NAME='NEW PHILADELPHIA CLEVER FIELD, OH US', TEMP=33.3, DEWP=21.8, SLP=1013.3, STP=979.9, VISIB=9.8, WDSP=7.1, MXSPD=15.0, GUST=29.9, MAX=45.0, MIN=23.0, PRCP=0.01, spotId=3215, SpotDate='2016-12-31', Time='12:0:0 AM', SunspotNumber=18.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSpot_join_Weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfSpotWeather = dfSpot_join_Weather.select(col('ts'), \n",
    "                                     date_format(noaaParquet[\"ts\"], 'yyyy-MM-dd h:m:s a').alias('ConditionId'), \n",
    "                                     col('StationId'), \n",
    "                                     col('spotId'), ) \\\n",
    "                                     .withColumn('ts', monotonically_increasing_id())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ts: long (nullable = false)\n",
      " |-- ConditionId: string (nullable = true)\n",
      " |-- StationId: long (nullable = true)\n",
      " |-- spotId: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36199"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSpotWeather.printSchema()\n",
    "dfSpotWeather.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>ConditionId</th>\n",
       "      <th>StationId</th>\n",
       "      <th>spotId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72522404852</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>3088099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>71862099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>71120099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>15333099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72254203999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72511493778</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>71808099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72203812897</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>83899099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72517014737</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72543094822</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>74594693786</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72445303994</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>1373099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>71114099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>71600099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72061999999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72341793988</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72515594761</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>3144099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>82400099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72503614757</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72535014848</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>3392099999</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72038200123</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72531753802</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72510514770</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72650604840</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2016-12-31 12:0:0 AM</td>\n",
       "      <td>72231012916</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169</th>\n",
       "      <td>300647711767</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72401693736</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36170</th>\n",
       "      <td>300647711768</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72622564776</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36171</th>\n",
       "      <td>300647711769</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72205453959</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36172</th>\n",
       "      <td>300647711770</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>74780413824</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36173</th>\n",
       "      <td>300647711771</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72258013960</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36174</th>\n",
       "      <td>300647711772</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72213713878</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36175</th>\n",
       "      <td>300647711773</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72636014840</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36176</th>\n",
       "      <td>300647711774</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>71823099999</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36177</th>\n",
       "      <td>300647711775</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72456013996</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36178</th>\n",
       "      <td>300647711776</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72248713935</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36179</th>\n",
       "      <td>300647711777</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>22887099999</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36180</th>\n",
       "      <td>300647711778</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72649994971</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36181</th>\n",
       "      <td>300647711779</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72671024164</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36182</th>\n",
       "      <td>300647711780</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72248953911</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36183</th>\n",
       "      <td>300647711781</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72508554756</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36184</th>\n",
       "      <td>300647711782</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72637014826</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36185</th>\n",
       "      <td>300647711783</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>3973099999</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36186</th>\n",
       "      <td>300647711784</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>6340099999</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36187</th>\n",
       "      <td>300647711785</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>78543011640</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36188</th>\n",
       "      <td>300647711786</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>70274025331</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36189</th>\n",
       "      <td>300647711787</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72247003901</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36190</th>\n",
       "      <td>300647711788</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72244753903</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36191</th>\n",
       "      <td>300647711789</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72504514758</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36192</th>\n",
       "      <td>300647711790</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72248613942</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36193</th>\n",
       "      <td>300647711791</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72456513920</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36194</th>\n",
       "      <td>300647711792</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72536614825</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36195</th>\n",
       "      <td>300647711793</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72552794978</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36196</th>\n",
       "      <td>300647711794</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72508714752</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36197</th>\n",
       "      <td>300647711795</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>72428704848</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36198</th>\n",
       "      <td>300647711796</td>\n",
       "      <td>2013-01-31 12:0:0 AM</td>\n",
       "      <td>74788012810</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36199 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ts           ConditionId    StationId  spotId\n",
       "0                 0  2016-12-31 12:0:0 AM  72522404852    3215\n",
       "1                 1  2016-12-31 12:0:0 AM   3088099999    3215\n",
       "2                 2  2016-12-31 12:0:0 AM  71862099999    3215\n",
       "3                 3  2016-12-31 12:0:0 AM  71120099999    3215\n",
       "4                 4  2016-12-31 12:0:0 AM  15333099999    3215\n",
       "5                 5  2016-12-31 12:0:0 AM  72254203999    3215\n",
       "6                 6  2016-12-31 12:0:0 AM  72511493778    3215\n",
       "7                 7  2016-12-31 12:0:0 AM  71808099999    3215\n",
       "8                 8  2016-12-31 12:0:0 AM  72203812897    3215\n",
       "9                 9  2016-12-31 12:0:0 AM  83899099999    3215\n",
       "10               10  2016-12-31 12:0:0 AM  72517014737    3215\n",
       "11               11  2016-12-31 12:0:0 AM  72543094822    3215\n",
       "12               12  2016-12-31 12:0:0 AM  74594693786    3215\n",
       "13               13  2016-12-31 12:0:0 AM  72445303994    3215\n",
       "14               14  2016-12-31 12:0:0 AM   1373099999    3215\n",
       "15               15  2016-12-31 12:0:0 AM  71114099999    3215\n",
       "16               16  2016-12-31 12:0:0 AM  71600099999    3215\n",
       "17               17  2016-12-31 12:0:0 AM  72061999999    3215\n",
       "18               18  2016-12-31 12:0:0 AM  72341793988    3215\n",
       "19               19  2016-12-31 12:0:0 AM  72515594761    3215\n",
       "20               20  2016-12-31 12:0:0 AM   3144099999    3215\n",
       "21               21  2016-12-31 12:0:0 AM  82400099999    3215\n",
       "22               22  2016-12-31 12:0:0 AM  72503614757    3215\n",
       "23               23  2016-12-31 12:0:0 AM  72535014848    3215\n",
       "24               24  2016-12-31 12:0:0 AM   3392099999    3215\n",
       "25               25  2016-12-31 12:0:0 AM  72038200123    3215\n",
       "26               26  2016-12-31 12:0:0 AM  72531753802    3215\n",
       "27               27  2016-12-31 12:0:0 AM  72510514770    3215\n",
       "28               28  2016-12-31 12:0:0 AM  72650604840    3215\n",
       "29               29  2016-12-31 12:0:0 AM  72231012916    3215\n",
       "...             ...                   ...          ...     ...\n",
       "36169  300647711767  2013-01-31 12:0:0 AM  72401693736    3168\n",
       "36170  300647711768  2013-01-31 12:0:0 AM  72622564776    3168\n",
       "36171  300647711769  2013-01-31 12:0:0 AM  72205453959    3168\n",
       "36172  300647711770  2013-01-31 12:0:0 AM  74780413824    3168\n",
       "36173  300647711771  2013-01-31 12:0:0 AM  72258013960    3168\n",
       "36174  300647711772  2013-01-31 12:0:0 AM  72213713878    3168\n",
       "36175  300647711773  2013-01-31 12:0:0 AM  72636014840    3168\n",
       "36176  300647711774  2013-01-31 12:0:0 AM  71823099999    3168\n",
       "36177  300647711775  2013-01-31 12:0:0 AM  72456013996    3168\n",
       "36178  300647711776  2013-01-31 12:0:0 AM  72248713935    3168\n",
       "36179  300647711777  2013-01-31 12:0:0 AM  22887099999    3168\n",
       "36180  300647711778  2013-01-31 12:0:0 AM  72649994971    3168\n",
       "36181  300647711779  2013-01-31 12:0:0 AM  72671024164    3168\n",
       "36182  300647711780  2013-01-31 12:0:0 AM  72248953911    3168\n",
       "36183  300647711781  2013-01-31 12:0:0 AM  72508554756    3168\n",
       "36184  300647711782  2013-01-31 12:0:0 AM  72637014826    3168\n",
       "36185  300647711783  2013-01-31 12:0:0 AM   3973099999    3168\n",
       "36186  300647711784  2013-01-31 12:0:0 AM   6340099999    3168\n",
       "36187  300647711785  2013-01-31 12:0:0 AM  78543011640    3168\n",
       "36188  300647711786  2013-01-31 12:0:0 AM  70274025331    3168\n",
       "36189  300647711787  2013-01-31 12:0:0 AM  72247003901    3168\n",
       "36190  300647711788  2013-01-31 12:0:0 AM  72244753903    3168\n",
       "36191  300647711789  2013-01-31 12:0:0 AM  72504514758    3168\n",
       "36192  300647711790  2013-01-31 12:0:0 AM  72248613942    3168\n",
       "36193  300647711791  2013-01-31 12:0:0 AM  72456513920    3168\n",
       "36194  300647711792  2013-01-31 12:0:0 AM  72536614825    3168\n",
       "36195  300647711793  2013-01-31 12:0:0 AM  72552794978    3168\n",
       "36196  300647711794  2013-01-31 12:0:0 AM  72508714752    3168\n",
       "36197  300647711795  2013-01-31 12:0:0 AM  72428704848    3168\n",
       "36198  300647711796  2013-01-31 12:0:0 AM  74788012810    3168\n",
       "\n",
       "[36199 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSpotWeather.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We check that we have no NULL elements in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that key fields have valid values (no nulls or empty)\n",
    "dfSpotWeather.createOrReplaceTempView(\"SpotWeatherTable\")\n",
    "SpotWeather_check = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM SpotWeatherTable\n",
    "    WHERE ts IS NULL OR ConditionId IS NULL OR StationId IS NULL OR spotId is NULL\n",
    "\"\"\")\n",
    "SpotWeather_check.show(1)\n",
    "SpotWeather_check.collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Fact table**\n",
    "\n",
    "*dfSpotWeather*\n",
    "* ts: timestap \n",
    "* ConditionId: Weather condition identifier from noaaParquet\n",
    "* StationId: Station id from noaaParquet\n",
    "* spotId: Spot id from cleanedSpots\n",
    "\n",
    "**Dim Table**\n",
    "\n",
    "*stationTable*\n",
    "* stationId: Station id from noaaParquet\n",
    "* longitude: Station longitude from noaaParquet\n",
    "* latitude: Station latitude from noaaParquet\n",
    "* elevation: Station elevation from noaaParquet\n",
    "* name: Station name from noaaParquet\n",
    "    \n",
    "*dateTable*\n",
    "* ts: timestamp from noaaParquet\n",
    "* hour: hour from noaaParquet\n",
    "* dayofmonth: day of the month from noaaParquet\n",
    "* weekofyear: week of the year from noaaParquet\n",
    "* month: month from noaaParquet\n",
    "* year: year from noaaParquet\n",
    "* dayofweek: day of the week from noaaParquet\n",
    "    \n",
    "*WeatherTable*\n",
    "* ConditionId: Weather condition identifier from noaaParquet\n",
    "* TEMP: Temperature reading from noaaParquet\n",
    "* DEWP: Dew Point reading from noaaParquet\n",
    "* SLP: Mean sea level pressure from noaaParquet \n",
    "* STP: Mean station pressure from noaaParquet\n",
    "* VISIB: Mean visibility from noaaParquet\n",
    "* WDSP: Mean wind speed from noaaParquet\n",
    "* MXSPD: Maximum sustained wind speed reported from noaaParquet \n",
    "* GUST: Maximum wind gust reported from noaaParquet \n",
    "* MAX: Maximum temperature reported from noaaParquet \n",
    "* MIN: Minimum temperature reported from noaaParquet \n",
    "* RCP: Total precipitation from noaaParquet\n",
    "    \n",
    "*spotTable*\n",
    "* spotsId: spot identifier from cleanedSpots\n",
    "* sunspotNumber: Monthly Mean Total Sunspot Number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Given the already large data set Spark is very usuful to deal with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data should be updated on a yearly basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I choose NoSQL as data model which is good for linear scalbility. Increasing the data set posese no problems. The Spark framework allows access for hundreds of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
